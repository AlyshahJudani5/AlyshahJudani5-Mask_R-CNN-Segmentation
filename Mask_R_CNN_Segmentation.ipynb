{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from skimage.draw import polygon\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n"
      ],
      "metadata": {
        "id": "diCsxzE0juum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = \"/content/Original.zip\"\n",
        "extract_path = \"image_data\"\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Successfully extracted '{zip_file_path}' to '{extract_path}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{zip_file_path}' not found.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "GbUSTI4EQvyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load annotation file\n",
        "annotation_path = '/content/labels_my-project-name_2025-01-23-07-57-12.json'\n",
        "image_folder = \"/content/image_data/Original\"\n",
        "\n",
        "# Load annotations\n",
        "with open(annotation_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "images = {img['id']: img for img in data['images']}\n",
        "annotations = data['annotations']\n",
        "categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "\n",
        "# Visualize the dataset\n",
        "def visualize_dataset(image_id, annotations, image_folder, images, categories):\n",
        "    img_info = images[image_id]\n",
        "    img_path = os.path.join(image_folder, img_info['file_name'])\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Plot the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Overlay annotations\n",
        "    for ann in annotations:\n",
        "        if ann['image_id'] == image_id:\n",
        "            category_name = categories[ann['category_id']]\n",
        "            segmentations = ann['segmentation']\n",
        "\n",
        "            for seg in segmentations:\n",
        "                # Convert flat list to (x, y) pairs\n",
        "                reshaped_seg = [(seg[i], seg[i + 1]) for i in range(0, len(seg), 2)]\n",
        "\n",
        "                # Draw segmentation polygon\n",
        "                poly = Polygon(reshaped_seg, closed=True, edgecolor='red', fill=False, linewidth=2, label=category_name)\n",
        "                plt.gca().add_patch(poly)\n",
        "\n",
        "            # Add category label\n",
        "            bbox = ann['bbox']\n",
        "            plt.text(\n",
        "                bbox[0], bbox[1] - 10, category_name, color='yellow', fontsize=10, bbox=dict(facecolor='black', alpha=0.5)\n",
        "            )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize each image with annotations\n",
        "for img_id in images.keys():\n",
        "    visualize_dataset(img_id, annotations, image_folder, images, categories)\n"
      ],
      "metadata": {
        "id": "2xyhBgvGjuun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load annotation file\n",
        "annotation_path = '/content/labels_my-project-name_2025-01-23-07-57-12.json'\n",
        "\n",
        "# Load annotations\n",
        "with open(annotation_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Creating a DataFrame for images\n",
        "image_data = []\n",
        "for img in data['images']:\n",
        "    image_data.append({\n",
        "        'id': img['id'],\n",
        "        'file_name': img['file_name'],\n",
        "        'width': img['width'],\n",
        "        'height': img['height']\n",
        "    })\n",
        "\n",
        "images_df = pd.DataFrame(image_data)\n",
        "\n",
        "# Creating a DataFrame for annotations\n",
        "annotation_data = []\n",
        "for ann in data['annotations']:\n",
        "    annotation_data.append({\n",
        "        'image_id': ann['image_id'],\n",
        "        'category_id': ann['category_id'],\n",
        "        'segmentation': ann['segmentation'],\n",
        "        'bbox': ann['bbox'],\n",
        "        'area': ann['area'],\n",
        "        'iscrowd': ann['iscrowd']\n",
        "    })\n",
        "\n",
        "annotations_df = pd.DataFrame(annotation_data)\n",
        "\n",
        "# Merge the two DataFrames based on image_id\n",
        "merged_df = pd.merge(annotations_df, images_df, left_on='image_id', right_on='id', how='inner')\n",
        "\n",
        "# Show the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "id": "HxcQjI97juuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, image_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        # Categories dictionary (id to name mapping)\n",
        "        self.categories = {1: 'name(en)', 2: 'name(urd)', 3: 'fathername(en)', 4: 'fathername(urd)'}  # Update this with actual category names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df['image_id'].unique())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df['image_id'].unique()[idx]\n",
        "        image_info = self.df[self.df['image_id'] == image_id].iloc[0]\n",
        "\n",
        "        # Load the image\n",
        "        img_path = os.path.join(self.image_folder, image_info['file_name'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Get annotations for the image\n",
        "        annotations = self.df[self.df['image_id'] == image_id]\n",
        "\n",
        "        boxes = []\n",
        "        masks = []\n",
        "        labels = []\n",
        "        area = []\n",
        "        iscrowd = []\n",
        "\n",
        "        # Convert annotations to appropriate format for Mask R-CNN\n",
        "        for _, ann in annotations.iterrows():\n",
        "            # Bounding box\n",
        "            bbox = ann['bbox']\n",
        "            boxes.append(bbox)\n",
        "\n",
        "            # Segmentation (polygon)\n",
        "            segmentation = ann['segmentation']\n",
        "            mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)\n",
        "            for seg in segmentation:\n",
        "                poly = np.array(seg).reshape((-1, 2))\n",
        "                rr, cc = polygon(poly[:, 1], poly[:, 0], mask.shape)\n",
        "                mask[rr, cc] = 1\n",
        "            masks.append(mask)\n",
        "\n",
        "            # Area\n",
        "            area.append(ann['area'])\n",
        "\n",
        "            # Iscrowd\n",
        "            iscrowd.append(ann['iscrowd'])\n",
        "\n",
        "            # Category\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        area = torch.as_tensor(area, dtype=torch.float32)\n",
        "        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        # Additional information (image_id, area, iscrowd, etc.)\n",
        "        image_id = torch.tensor([image_id])\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'masks': masks,\n",
        "            'image_id': image_id,\n",
        "            'area': area,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transform:\n",
        "            image, target = self.transform(image, target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "# Example of using the dataset class\n",
        "dataset = CustomDataset(df=merged_df, image_folder=\"/content/image_data/Original\")\n",
        "\n",
        "# one sample\n",
        "image, target = dataset[0]\n",
        "print(image.size, target)\n"
      ],
      "metadata": {
        "id": "n7xnhbTfjuuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-trained Mask R-CNN model\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# the classifier (plus background)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 4 + 1)  # 4 categories + 1 background\n",
        "\n",
        "# Mask predictor\n",
        "in_mask_features = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_mask_features, 256, 4 + 1)  # 4 categories + 1 background\n",
        "\n",
        "# Move model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "T1mtk-B9juup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = T.Compose([T.ToTensor()])  # Convert images to tensor\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Optimizer Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Track losses for visualization\n",
        "losses_list = []\n",
        "\n",
        "# Training\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0  # Track the loss for this epoch\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        # Convert images to tensors and move them to the device\n",
        "        images = [transform(image).to(device) for image in images]  # Applying transform here\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += losses.item()\n",
        "\n",
        "    # Average loss for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    losses_list.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n",
        "\n",
        "# Plot training loss curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), losses_list, label=\"Training Loss\", color='b')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y1JxsA1tjuup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check the value at index 0\n",
        "\n",
        "merged_df.iloc[0]"
      ],
      "metadata": {
        "id": "4XNgpT7MSb_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: list all the bounding boxes and masks\n",
        "\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "# ... (rest of your imports and code)\n",
        "\n",
        "# Load annotation file\n",
        "annotation_path = '/content/labels_my-project-name_2025-01-23-07-57-12.json'\n",
        "\n",
        "# Load annotations\n",
        "with open(annotation_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "annotations = data['annotations']\n",
        "\n",
        "# Iterate through annotations and print bounding boxes and segmentation masks\n",
        "for ann in annotations:\n",
        "    print(f\"Image ID: {ann['image_id']}\")\n",
        "    print(f\"Bounding Box: {ann['bbox']}\") # [x_min, y_min, width, height]\n",
        "    print(f\"Segmentation Mask: {ann['segmentation']}\") # List of polygon coordinates\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "7WQIcS5zRlHU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}